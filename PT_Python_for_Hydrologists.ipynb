{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uma breve introdução a Python para Análises Hidrológicas\n",
    "<br>\n",
    "<img style=\"float: left; padding-right: 15px; padding-left: 0px;\" src=\"source/logo_flood_proofs.png\" width=\"260px\" align=”left” >\n",
    "\n",
    "<div style=\"text-align: justify\">Este é um Jupyter Notebook, um ambiente de desenvolvimento interactivo baseado na web que permite criar e partilhar códigos Python.\n",
    "Primeiro, o que é **Python***? Python é uma linguagem de programação de alto nível e de uso geral. Pode ser utilizado para escrever software numa grande variedade de domínios de aplicação, incluindo a hidrologia. Python pode ser utilizado para efectuar cálculos numéricos, análises estatísticas ou para aceder e plotar dados (mesmo grandes conjuntos de dados). <br>\n",
    "No caderno de notas Jupyter, a *Python shell* está incorporada. A **shell** é onde se pode escrever e executar uma linha (ou múltiplas linhas) de código.\n",
    "Python é de código aberto, e estão disponíveis vários pacotes que cobrem muitos campos científicos e tecnológicos.\n",
    "\n",
    "Vamos começar a utilizar Python como **calculador***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "190/3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se necessário, podemos atribuir este resultado a uma **variável**, e utilizar a variável para cálculos futuros ou para outras operações (como a conversão para o inteiro e a visualização do resultado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 190/3\n",
    "new_result = result - 14\n",
    "int_result = int(new_result)\n",
    "print(int(int_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se quisermos realizar alguns cálculos mais complexos? Podemos importar o pacote **math**, carregando várias funções matemáticas (tais como a raiz quadrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "sqrt_result = math.sqrt(int_result)\n",
    "print(sqrt_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se quisermos trabalhar não com um único valor, mas com um **vector** composto por múltiplos valores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = [1,4,100,3,-2]\n",
    "print(array)\n",
    "print('------> complete array maximum: ' + str(np.max(array)))\n",
    "array_nan = array\n",
    "array_nan[2] = np.nan\n",
    "print(array_nan)\n",
    "print('------> incomplete array maximum: ' + str(np.max(array)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será o último resultado correcto? Não deveria ser 4 o novo valor máximo? Podemos utilizar uma função específica para contabilizar os \"Nan\" ou os valores em falta: *np.nanmax* (parte de pacote numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------> incomplete array maximum: ' + str(np.nanmax(array)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando de Séries Temporais (timeseries)\n",
    "Podemos gerar **séries temporais** (múltiplos valores com data associada) e exibi-la em um gráfico? Claro que sim!\n",
    "Comecemos por importar algumas bibliotecas úteis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import wget\n",
    "import os\n",
    "\n",
    "# We can also define personal function, this one for example allow to visualize the output of dropdowns menus\n",
    "def on_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            print(\"Selected value: \" + change['new'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agora proceder com uma série cronológica aleatória!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(365), index=pd.date_range('1/1/2010', periods=365))\n",
    "plt.figure()\n",
    "ts.plot(style='b-', label='Random timeseries')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mais interessante é trabalhar com as séries temporais existentes. A NOAA fornece um conjunto de dados global de valores diários de precipitação e temperatura, o **Global Historical Climate Network Daily** (https://www.ncdc.noaa.gov/ghcn-daily-description).\n",
    "O conjunto de dados pode ser consultado por país seleccionando-o a partir do seguinte menu descendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of available countries and generate dropdown selector\n",
    "with open('source/ghcnd-countries.txt', 'r') as file:\n",
    "    list_country = [line for line in file]\n",
    "country_chooser = widgets.Dropdown(\n",
    "    options=['Choose a country'] + list_country,\n",
    "    value='Choose a country',\n",
    "    description='Country:',\n",
    "    disabled=False,\n",
    ")\n",
    "country_chooser.observe(on_change)\n",
    "display(country_chooser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao executar a próxima peça de código será mostrado um menu descendente da estação disponível para o país seleccionado. Por favor, seleccione a estação de interesse.\n",
    "**NB!** Alguns países (Brasil, Austrália e EUA) têm demasiadas estações e podem quebrar o sistema, para esses países a selecção manual da estação é viável!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the list of the available stations\n",
    "country_code = country_chooser.value[0:2]\n",
    "list_stations = pd.read_fwf('source/ghcnd-stations.txt',\n",
    "                            widths=[2,9,9,10,7,4,31,3,10],\n",
    "                            header=None, usecols=[0,1,2,3,4,6], \n",
    "                            names=['COUNTRY','CODE','LAT','LON','ELEV','NAME'])\n",
    "list_stations_in = list_stations.loc[list_stations['COUNTRY']==country_code].sort_values('NAME', ascending=True)\n",
    "\n",
    "if len(list_stations_in)<4000:\n",
    "    station_chooser = widgets.Dropdown(\n",
    "        options=['Choose a station'] + list(list_stations_in['COUNTRY'] + list_stations_in['CODE'] + ' ' + list_stations_in['NAME']),\n",
    "        value='Choose a station',\n",
    "        description='Station:',\n",
    "        disabled=False,\n",
    "    )\n",
    "    station_chooser.observe(on_change)\n",
    "    display(station_chooser)\n",
    "else:\n",
    "    print('Station list is too long! Please, manually choose the station code from the available list at the web address https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt among the ones with first column starting with ' + country_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima peça de código descarregará a série a partir da série NOAA e analisará as variáveis disponíveis. \n",
    "Escolher a variável para a análise a partir do menu descendente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert information only for manually selecting the station code (for Brazil, Austalia and US)\n",
    "section_code =  None     # es: 'BR00B7-0400'\n",
    "section_name = None      # es: 'SAO JOAO DE IRACEMA'\n",
    "###############################################################################################\n",
    "\n",
    "if section_code is None:\n",
    "    section_code = station_chooser.value.split(' ', 1)[0]\n",
    "    section_name = station_chooser.value.split(' ', 1)[1]\n",
    "file_name = section_code +'.csv'\n",
    "out_path = 'meteo/' + file_name\n",
    "\n",
    "# Check if the file has been already downloaded\n",
    "if os.path.isfile(out_path):\n",
    "    print('Section ' + section_code + ' ' + section_name + ' already downloaded!')\n",
    "    print('DONE!')\n",
    "else:\n",
    "    print('Dowloading section ' + section_code + ' ' + section_name + '... It can take some times!')\n",
    "    https_address = 'https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/'\n",
    "    wget.download(https_address + file_name, out = out_path)\n",
    "    print('DONE!')\n",
    "    \n",
    "# Open the file and analyse the available variables\n",
    "info_station = pd.read_csv(out_path, header=0, usecols=['STATION','NAME','LATITUDE','LONGITUDE','ELEVATION'], nrows=1)\n",
    "full_series = pd.read_csv(out_path, header=0, index_col='DATE', parse_dates=True, usecols=lambda c: c in {'DATE','PRCP','SNWD','TMAX','TMIN','TAVG'}) #, usecols=[1,2,3], names=['date','type','val'])\n",
    "dic_vars={'precipitation':['PRCP', 'Rainfall(mm)'], 'temperature mean':['TAVG','Temperature(°C)'], 'temperature max':['TMAX','Temperature(°C)'], 'temperature min':['TMIN','Temperature(°C)'], 'snow depth':['SNWD', 'Snow depth(cm)']}\n",
    "\n",
    "available_vars = [i for i in dic_vars if dic_vars[i][0] in full_series.columns]\n",
    "\n",
    "var_chooser = widgets.Dropdown(\n",
    "    options=['Choose a variable'] + available_vars,\n",
    "    value='Choose a variable',\n",
    "    description='Vars available:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "var_chooser.observe(on_change)\n",
    "display(info_station.style.hide_index())\n",
    "display(var_chooser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos representar interactivamente uma das séries de tempos disponíveis, escolhendo a estação, a variável e também os limites de tempo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert information only for choosing a sub-period of the whole series\n",
    "time_start = None    # Set a date in the format 'YYYY-MM-DD' or None for plot the series from the beginning\n",
    "time_end = None      # Set a date in the format 'YYYY-MM-DD' or None for plot the series up to the end\n",
    "####################################################################\n",
    "\n",
    "# Read data series\n",
    "variable = var_chooser.value\n",
    "temp_series = full_series[[dic_vars[variable][0]]]/10\n",
    "\n",
    "# Set time range\n",
    "time_start = temp_series.first_valid_index() if time_start is None else pd.to_datetime(time_start,format='%Y-%m-%d')\n",
    "time_end = temp_series.last_valid_index() if time_end is None else pd.to_datetime(time_end,format='%Y-%m-%d')\n",
    "if time_start > time_end:\n",
    "    raise ValueError(\"time_start is larger than time_end, verify your data!\")\n",
    "time_range = pd.date_range(time_start,time_end,freq='1D')\n",
    "temp_series = temp_series.reindex(time_range)\n",
    "\n",
    "display(temp_series)\n",
    "\n",
    "# Manage plot\n",
    "ax = temp_series.plot(style='b', title=variable + ' at ' + section_name, figsize=(15,5))\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(dic_vars[variable][1])\n",
    "ax.get_legend().remove()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As séries cronológicas podem ser facilmente geridas com Python para operações estatísticas e de resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resample frequency can be set, e.g., to annual 'Y' or monthly 'M'\n",
    "temp_resampled_max = temp_series.reindex(time_range).resample('M').max()\n",
    "temp_resampled_min = temp_series.reindex(time_range).resample('M').min()\n",
    "temp_resampled_avg = temp_series.reindex(time_range).resample('M').mean()\n",
    "\n",
    "# Manage plot\n",
    "ax = temp_resampled_max.plot(style='r', title=variable + ' at ' + section_name, figsize=(15,5))\n",
    "temp_resampled_min.plot(style='b',ax=ax)\n",
    "temp_resampled_avg.plot(style='g',ax=ax)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(dic_vars[variable][1])\n",
    "plt.legend(['max','min','avg'])\n",
    "plt.savefig(section_name + '_' + variable + '.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood frequency analysis using Python\n",
    "Podemos utilizar a Python para calcular as estatísticas de cheias numa série temporais de caudal. Referência a *hydro-informatics.github.io*<br>\n",
    "\n",
    "A ocorrência de eventos (extremos) de inundação relevantes pode ser expressa como **período de retorno**, expressando o intervalo médio de recorrência de um evento de uma certa magnitude em unidades de tempo. É o inverso da **probabilidade de superação** (a probabilidade de um evento de certa magnitude ou superior).<br>\n",
    "Um pressuposto significativo no cálculo do período de retorno é que os eventos individuais são considerados independentes. Isto significa que, para um determinado ano, a probabilidade de ocorrência de uma inundação de 100 anos é de 1/100.\n",
    "Aqui abaixo uma tabela que mostra os intervalos de recorrência e as probabilidades de ocorrências relacionadas.\n",
    "\n",
    "| Período de retorno (anos) | Probabilidade anual de superação (%) |\n",
    "| --- | --- |\n",
    "| 2 | 50 |\n",
    "| 5 | 10 |\n",
    "| 10 | 10 |\n",
    "| 50 | 2 |\n",
    "| 100 | 1 |\n",
    "| 500 | 0.2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No início devemos importar algumas bibliotecas úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import wget\n",
    "import os\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, devemos importar os **dados de caudal**. \n",
    "Vamos ver o que os ficheiros da série \"txt\" podem ser encontrados dentro da pasta \"discharge\".\n",
    "Outros dados podem ser descarregados a partir do portal de dados GRDC através da realização de um pedido personalizado (https://portal.grdc.bafg.de/applications/public.html?publicuser=PublicUser#dataDownload/Stations). O pedido será avaliado pelo fornecedor de dados e dentro de pouco tempo será fornecido um e-mail com uma url de descarregamento. \n",
    "A url pode ser inserida e analisada directamente com esta ferramenta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify this section by inserting the download address provided by the GRDC website for download more data\n",
    "# es: download_link = 'https://portal.grdc.bafg.de/grdcdownload/external/53c13313-e359-4f61-bb9d-d803b2ab74e1/2021-07-01_16-52.zip'\n",
    "download_link = None\n",
    "############################################################################################################\n",
    "\n",
    "if not download_link is None:\n",
    "    os.makedirs('temp', exist_ok=True)\n",
    "    wget.download(download_link, out= 'temp/')\n",
    "    with zipfile.ZipFile('temp/' + os.path.basename(download_link), 'r') as zip_ref:\n",
    "        zip_ref.extractall('discharge/')\n",
    "    \n",
    "files = glob.glob(\"discharge/*.txt\")\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lista não nos diz muito sobre o conteúdo do ficheiro, podemos abrir um destes ficheiros para compreender o conteúdo de cada ficheiro \n",
    "\n",
    "**NOTE! A numeração Python começa a partir de 0!!**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a preview of the file\n",
    "number_of_lines = 40\n",
    "\n",
    "with open(files[0],'rb') as file:\n",
    "    for i in np.arange(0,number_of_lines,1): \n",
    "        line = file.readline().decode('ISO-8859-1')\n",
    "        print(str(i) + ' ' + line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As linhas entre 8 e 18 de cada ficheiro contêm toda a informação sobre a estação, podemos usar a capacidade python de gerir diferentes tipos de ficheiro para resumir essas informações numa tabela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 11 lines after line 8 (Python numbering starts from 0!)\n",
    "for ind, file in enumerate(files,0):\n",
    "    data = pd.read_csv(file, skiprows=8, nrows=11, sep=\":\", encoding='ISO-8859-1', header=None, names=['cod','val'])    \n",
    "    if ind == 0:\n",
    "        list_vars = [i.replace('# ','') for i in data['cod']]\n",
    "        df_stations = pd.DataFrame(index=np.arange(0,len(files),1),columns=list_vars)\n",
    "    data['cod'] = list_vars\n",
    "    data = data.set_index(['cod'])\n",
    "    for var in list_vars:\n",
    "        df_stations.loc[ind][var] = data.loc[var].values[0].strip()\n",
    "\n",
    "df_stations = df_stations.set_index([\"GRDC-No.\"])\n",
    "display(df_stations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agora escolher que estação a analisar, fornecendo o seu código para identificar o ficheiro relacionado, vamos começar, por exemplo, com o **AWASH WENZ em MELKA KUNTIRE** (COD: 1577100):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please, specify an available station code\n",
    "station_code = '1577100'\n",
    "##############################################################################################\n",
    "\n",
    "# Read data from line 37\n",
    "df = pd.read_csv(\"discharge/\" + station_code + \"_Q_Day.Cmd.txt\",\n",
    "                 header=None,\n",
    "                 sep=\";\",\n",
    "                 skiprows=37,\n",
    "                 names=[\"Date\", \"Time\",\"Q\"],\n",
    "                 parse_dates=[0],\n",
    "                 index_col=[\"Date\"])\n",
    "df['Q']=df['Q'].astype(float)\n",
    "ax = df.plot(title=df_stations.loc[station_code][\"River\"] + \" at \" + df_stations.loc[station_code][\"Station\"], figsize=(15,5))\n",
    "ax.set_ylabel('Q (m3/s)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem valores nulos na série, que correspondem a valores nulos, podemos geri-los repalhando com \"np.nan\", que é o valor nulo standard do numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace negative values with \"null\"\n",
    "df.loc[df['Q']<0,'Q']=np.nan\n",
    "ax = df.plot(title=df_stations.loc[station_code][\"River\"] + \" at \" + df_stations.loc[station_code][\"Station\"], figsize=(15,5))\n",
    "ax.set_ylabel('Q (m3/s)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é a série cronológica completa: temos de seleccionar apenas os **máximos anuais**. É bastante simples com *pandas dataframe*, podemos fazer uma nova amostragem do nosso conjunto de dados (que foi indexado com datas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample using the annual maximum value\n",
    "df_ymax = df.resample(\"Y\").max()\n",
    "df_ymax[\"year\"] = df_ymax.index.year\n",
    "df_ymax.reset_index(inplace=True, drop=True)\n",
    "df_ymax = df_ymax.dropna()\n",
    "print(df_ymax)\n",
    "\n",
    "# Manage plot\n",
    "df_ymax.plot(kind='scatter',x='year',y='Q',color='red', figsize=(15,5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise do período de retorno\n",
    "Devemos calcular a probabilidade de excedência *Pr*, e o intervalo de recorrência resultante.\n",
    "Pr is defined as: $Pr_{i} = \\frac{(n-i+1)}{n+1}$\\\n",
    "Onde *n* é o número total de anos de observação e *i* é a posição do evento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in increasing order\n",
    "df_ymax_sorted = df_ymax.sort_values(by=\"Q\")\n",
    "n = df_ymax_sorted.shape[0]\n",
    "df_ymax_sorted.insert(0, \"rank\", range(1, 1 + n))\n",
    "print(df_ymax_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **probabilidade de superação** ( *pr* ) pode ser calculada aplicando a fórmula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ymax_sorted[\"pr\"] = (n - df_ymax_sorted[\"rank\"] + 1) / (n + 1)\n",
    "print(df_ymax_sorted.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **intervalo de recorrência** ( *período de retorno* ) é o inverso da probabilidade, portanto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ymax_sorted[\"return-period\"] = 1 / df_ymax_sorted[\"pr\"]\n",
    "print(df_ymax_sorted.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez criada a tabela (*dataframe*) com toda a informação necessária (**Probabilidade** e **Período de retorno**) podemos visualizá-la para mostrar o intervalo de recorrência de cada caudal observado.  Vale a pena mencionar que esta análise e o gráfico resultante se referem apenas aos valores observados.<br>\n",
    "Para extrapolar o intervalo de recorrência para além do período de observação (os valores de inundação de 1 em 100 anos, por exemplo) é necessário um modelo de previsão (Gumbel, GEV, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ymax_sorted.plot.scatter(y=\"Q\",\n",
    "                         x=\"return-period\",\n",
    "                         title=\"Return period [years] \",\n",
    "                         color='blue',\n",
    "                         grid=True,\n",
    "                         fontsize=14,\n",
    "                         logy=False,\n",
    "                         label=\"Sorted values\",\n",
    "                         figsize=(15,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isto é para esta breve introdução prática a Python! \n",
    "\n",
    "## Pode exercitar-se um pouco:\n",
    " \n",
    "### Exercício 1\n",
    "\n",
    "Escolher a estação meteorológica de Tirana na Albânia:\n",
    "* qual é o valor máximo de temperatura alcançado na série temporais? (a partir do gráfico, lembre-se que também pode adicionar linhas de código ao bloco de notas jupyter se quiser. Ajuda: use a função np.max)\n",
    "\n",
    "Escolha outra estação meteorológica noutro país à sua escolha:\n",
    "* guarde o gráfico de chuva. Carregar a png resultante na plataforma Moodle.\n",
    "\n",
    "### Exercício 2\n",
    "\n",
    "Escolher a estação hidrológica no rio Buzi (código do *dataframe*):\n",
    "\n",
    "* qual é o valor de caudal para o Período de Retorno = 5?\n",
    "* qual é o valor de caudal com uma probabilidade de superação = 0.5?\n",
    "\n",
    "Escolha outra estação hidrológica em Moçambique:\n",
    "\n",
    "* pode traçar os períodos de retorno numa escala logarítmica (para y)? Guarde o gráfico. Carregar a png resultante na plataforma Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
